# Multi-modal Hierarchical Framework for Patient-level Pathology Analysis

This repository provides the official implementation of our multi-modal hierarchical (MH) framework for patient-level cancer staging based on whole slide images (WSIs) and textual descriptions.  
We introduce a Bi-Cross Attention (BCA) mechanism to achieve explicit cross-modal alignment between visual and textual features, and propose an Attention Gated Filter to select the most informative image patches for efficient diagnosis.  
Our hierarchical design aggregates information across multiple WSIs per patient, achieving state-of-the-art performance on the CAMELYON17 dataset for both slide-level and patient-level classification tasks.

